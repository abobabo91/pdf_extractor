


import streamlit as st
st.set_page_config(layout="wide")
import pandas as pd
import numpy as np
import os
import PyPDF2
import pdf2image
import pytesseract
from io import BytesIO
import openai
from openai import OpenAI
import tiktoken
import re


MODEL_PRICES = {
    "gpt-4.1": {"input": 1.25, "output": 10.00},
    "gpt-4o": {"input": 2.50, "output": 10.00},
    "gpt-4.1-mini": {"input": 0.25, "output": 2.00},
    "gpt-4.1-nano": {"input": 0.05, "output": 0.40},
}


def df_ready(df, required_cols=None):
    """Ellen≈ërzi, hogy a df nem √ºres √©s (opcion√°lisan) tartalmazza a k√∂telez≈ë oszlopokat."""
    if not isinstance(df, pd.DataFrame) or df is None or df.empty:
        return False
    if required_cols:
        return all(col in df.columns for col in required_cols)
    return True

def need_msg(missing_list):
    bullets = "\n".join([f"- {m}" for m in missing_list])
    st.warning(f"Az √∂sszef≈±z√©shez a k√∂vetkez≈ëk hi√°nyoznak vagy √ºresek:\n{bullets}")

def count_tokens(text, model="gpt-4o"):
    encoder = tiktoken.encoding_for_model(model)
    tokens = encoder.encode(text)
    return len(tokens)

def replace_successive_duplicates(df, column_to_compare, columns_to_delete):
    result = df.copy()
    col = column_to_compare
    mask = result[col] == result[col].shift()
    for col in columns_to_delete:
        result.loc[mask, col] = np.nan
    return result

def extract_text_from_pdf(uploaded_file):
    """Megpr√≥b√°lja sz√∂vegesen kinyerni a PDF tartalm√°t, OCR-rel kieg√©sz√≠tve, ha sz√ºks√©ges."""
    file_name = uploaded_file.name
    pdf_content = ""

    try:
        pdf_reader = PyPDF2.PdfReader(uploaded_file)
        for page in pdf_reader.pages[:]:
            pdf_content += page.extract_text() or ""
    except Exception as e:
        st.error(f"Hiba a(z) {file_name} f√°jl olvas√°sakor: {e}")
        return None

    if len(pdf_content.strip()) < 100:
        pdf_content = ""
        try:
            uploaded_file.seek(0)
            images = pdf2image.convert_from_bytes(uploaded_file.read())
#            images = pdf2image.convert_from_bytes(uploaded_file.read(), poppler_path = r"C:\poppler-24.08.0\Library\bin") local
            for img in images:
                pdf_content += pytesseract.image_to_string(img, lang="hun")
        except Exception as e:
            st.error(f"OCR hiba a(z) {file_name} f√°jln√°l: {e}")
            return None

    if len(pdf_content) > 500000:
        st.write(file_name + " t√∫l hossz√∫, csak az els≈ë 5000 karakter ker√ºl feldolgoz√°sra.")
        pdf_content = pdf_content[:5000]

    return pdf_content

def generate_gpt_prompt(text):
    """Generates a clear, structured GPT prompt for invoice data extraction."""
    return (
        "You are given the extracted text of a Hungarian invoice PDF. "
        "The PDF may contain multiple invoices merged together. "
        "Your task is to extract the following **9 data fields** for each invoice:\n\n"
        "1. Seller name (string)\n"
        "2. Buyer name (string)\n"
        "3. Invoice number (string)\n"
        "4. Invoice date (string, e.g. '2024.04.01')\n"
        "5. Total gross amount (integer)\n"
        "6. Total net amount (integer)\n"
        "7. VAT amount (integer)\n"
        "8. Currency (string: 'HUF' or 'EUR')\n"
        "9. Exchange rate (integer, use 1 if invoice is in HUF)\n\n"
        "**Important formatting instructions:**\n"
        "- Use semicolon (`;`) to separate the 9 fields.\n"
        "- Use **one line per invoice**.\n"
        "- Do **not** include field numbers (e.g. '1)', '2)' etc.) in the output.\n"
        "- Write all numeric fields as plain integers (e.g. `1500000`).\n"
        "- **Do not use thousands separators** (e.g. `.`) or decimal commas (`,`).\n"
        "- Note: In Hungarian, decimal separators are commas (`,`) instead of dots (`.`), "
        "but you must ignore this and always output plain integers.\n"
        "- Do **not** include any explanation, headings, or extra text ‚Äî just the data rows.\n\n"
        "Extracted text:\n"
        f"{text}"
    )


def extract_data_with_gpt(file_name, text, model_name):
    """A kiv√°lasztott GPT modellel kinyeri a strukt√∫r√°lt adatokat a PDF sz√∂vegb≈ël."""
    gpt_prompt = generate_gpt_prompt(text)

    try:
        client = OpenAI(api_key=openai.api_key)
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": ""},
                {"role": "user", "content": gpt_prompt}],
            max_completion_tokens=5000,
            timeout=30
        )

        raw_output = response.choices[0].message.content.strip()
        rows = raw_output.split("\n")

        parsed_rows = []
        for row in rows:
            parts = row.strip().split(";")
            if len(parts) != 9:
                st.warning(f"Hib√°s sor ({file_name}): {row}")
                continue

            cleaned_parts = [re.sub(r"^\s*\d+\)\s*", "", p.strip()) for p in parts]
            parsed_rows.append([file_name] + cleaned_parts)

        return parsed_rows, count_tokens(gpt_prompt)

    except Exception as e:
        st.error(f"A {model_name} feldolgoz√°s sikertelen volt: {file_name} ‚Äì {e}")
        return [], 0



def normalize_number(value):
    """Converts numeric-looking strings or floats to int. Removes all formatting."""
    try:
        if pd.isna(value):
            return None
        if isinstance(value, (int, float)):
            return int(round(value))
        # Remove thousands separators ('.' or ',' or space), allow decimals
        cleaned = str(value).replace(" ", "").replace(",", "").replace(".", "")
        return int(cleaned)
    except:
        return None



def compare_with_tolerance(val1, val2, tolerance=500):
    try:
        val1 = normalize_number(val1)
        val2 = normalize_number(val2)
        if val1 is None or val2 is None:
            return False
        return abs(val1 - val2) <= tolerance
    except:
        return False

def get_minta_amount(row, huf_col="√ârt√©k", eur_col="√ârt√©k deviza", currency_col="Devizanem"):
    """Returns the value in correct currency column based on Devizanem."""
    try:
        dev = str(row[currency_col]).strip().upper()
        if dev == "EUR":
            return normalize_number(row[eur_col])
        else:
            return normalize_number(row[huf_col])
    except:
        return None


def compare_gpt_with_minta(df_minta, df_extracted, invoice_col_minta="Bizonylatsz√°m", invoice_col_extracted="Sz√°mlasz√°m", tolerance=5):
    # Merge on invoice number
    df_merged = pd.merge(df_minta, df_extracted, how="outer", left_on=invoice_col_minta, right_on=invoice_col_extracted)

    # Compare amounts
    df_merged["Brutt√≥ egyezik?"] = df_merged.apply(
        lambda row: compare_with_tolerance(
            get_minta_amount(row, huf_col="√ârt√©k", eur_col="√ârt√©k deviza", currency_col="Devizanem"),
            normalize_number(row["Brutt√≥ √°r"]),
            tolerance
        ),
        axis=1
    )

    # Optional: add summary column
    df_merged["Minden egyezik?"] = df_merged["Brutt√≥ egyezik?"].apply(lambda x: "‚úÖ Igen" if x else "‚ùå Nem")

    return df_merged


def merge_with_minta(df_extracted, df_minta, invoice_col_extracted="Sz√°mlasz√°m", invoice_col_minta="Bizonylatsz√°m"):
    df_merged = pd.merge(df_minta, df_extracted, how='outer', left_on=invoice_col_minta, right_on=invoice_col_extracted)
    matched = df_merged[invoice_col_extracted].notna().sum()
    total = len(df_minta)
    unmatched = total - matched
    match_rate = round(100 * matched / total, 2)
    
    stats = {
        "√ñsszes minta sor": total,
        "Tal√°latok sz√°ma": matched,
        "Hi√°nyz√≥ tal√°latok": unmatched,
        "Egyez√©si ar√°ny (%)": match_rate
    }

    return df_merged, stats



# Inicializ√°ljuk a session state v√°ltoz√≥kat
if 'extracted_text_from_invoice' not in st.session_state:
    st.session_state.extracted_text_from_invoice = []
if 'extracted_data' not in st.session_state:
    st.session_state.extracted_data = []
if 'df_extracted' not in st.session_state:
    st.session_state.df_extracted = pd.DataFrame()
if 'df_minta' not in st.session_state:
    st.session_state.df_minta = pd.DataFrame()
if 'df_nav' not in st.session_state:
    st.session_state.df_nav = pd.DataFrame()
if 'df_karton' not in st.session_state:
    st.session_state.df_karton = pd.DataFrame()
if 'df_merged' not in st.session_state:
    st.session_state.df_merged = pd.DataFrame()
if 'df_merged_full' not in st.session_state:
    st.session_state.df_merged_full = pd.DataFrame()
if 'number_of_tokens' not in st.session_state:
    st.session_state.number_of_tokens = 0

openai.organization = "org-i7aicv7Qc0PO4hkTCT4N2BqR"
openai.api_key = st.secrets['openai']["OPENAI_API_KEY"]

st.title("üìÑ Sz√°mlaadat-kinyer≈ë alkalmaz√°s")

col_pdf, col_excel = st.columns([1, 1])  # nagyobb bal oldali has√°b

with col_pdf:
    st.subheader("üìÇ PDF-ek kinyer√©se")
    
    st.write("1) T√∂lts fel egy vagy t√∂bb **magyar nyelv≈± sz√°ml√°t (PDF)**, amelyekb≈ël a rendszer kiolvassa a legfontosabb adatokat.")
    
    # 0) F√°jl felt√∂lt≈ë
    uploaded_files = st.file_uploader("üì§ PDF f√°jlok felt√∂lt√©se", type=["pdf"], accept_multiple_files=True)
    
    selected_model = st.selectbox(
        "V√°lassz modellt az adatkinyer√©shez:",
        ["gpt-4.1", "gpt-4o", "gpt-4.1-mini", "gpt-4.1-nano"],
        index=0,
        help="√Årak per 1M token:\n"
             "- gpt-4.1: \$1.25 input / \$10 output\n"
             "- gpt-4o: \$2.50 input / \$10 output\n"
             "- gpt-4.1-mini: \$0.25 input / \$2 output\n"
             "- gpt-4.1-nano: \$0.05 input / \$0.40 output"
    )


    
    # 1) PDF feldolgoz√°s
    if st.button("üìë Adatkinyer√©s a PDF-b≈ël"):  
        st.session_state.extracted_text_from_invoice = []      
        if uploaded_files:
            if len(uploaded_files) > 200:
                st.write("‚ö†Ô∏è Az els≈ë 100 f√°jl ker√ºl feldolgoz√°sra.")
    
            for uploaded_file in uploaded_files[:200]:
                file_name = uploaded_file.name
                pdf_text = extract_text_from_pdf(uploaded_file)
    
                if pdf_text is None:
                    continue
    
                st.session_state.extracted_text_from_invoice.append([file_name, pdf_text])
        else:
            st.warning("‚ö†Ô∏è K√©rlek, t√∂lts fel legal√°bb egy PDF f√°jlt.")
    
        # 2) GPT adatkinyer√©s
        st.session_state.extracted_data = []
        if st.session_state.extracted_text_from_invoice:
            for file_name, pdf_content in st.session_state.extracted_text_from_invoice:
                extracted_rows, tokens = extract_data_with_gpt(file_name, pdf_content, selected_model)
                if extracted_rows:
                    st.session_state.extracted_data.extend(extracted_rows)
                    st.session_state.number_of_tokens += tokens
                    st.write(f"{file_name} feldolgoz√°sa k√©sz.")

    
        if st.session_state.extracted_data:
            st.session_state.df_extracted = pd.DataFrame(
                st.session_state.extracted_data,
                columns=["F√°jln√©v", "Elad√≥", "Vev≈ë", "Sz√°mlasz√°m", "Sz√°mla kelte", "Brutt√≥ √°r", "Nett√≥ √°r", "√ÅFA", "Deviza", "√Årfolyam"]
            )
            st.session_state.df_extracted["Sz√°mlasz√°m"] = st.session_state.df_extracted["Sz√°mlasz√°m"].astype(str)
            st.session_state.df_extracted["1"] = np.nan

    
    if len(st.session_state.df_extracted) > 0:        
        st.write("‚úÖ **Adatok kinyerve!** Az al√°bbi t√°bl√°zat tartalmazza az eredm√©nyeket:")
        st.dataframe(st.session_state.df_extracted)
    
        extract_csv = st.session_state.df_extracted.to_csv(index=False).encode("utf-8")
        st.download_button("üì• Kinyert adatok let√∂lt√©se CSV-ben", extract_csv, "kinyert_adatok.csv", "text/csv", key="letoltes-csv")
        
        buffer = BytesIO()
        with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
            st.session_state.df_extracted.to_excel(writer, sheet_name='Adatok', index=False)
            writer.close()
            st.download_button(
                label="üì• Kinyert adatok let√∂lt√©se Excelben",
                data=buffer,
                file_name='kinyert_adatok.xlsx',
                mime='application/vnd.ms-excel'
            )


    # Token √°r becsl√©s
    price_input = st.session_state.number_of_tokens * MODEL_PRICES[selected_model]["input"] / 1_000_000
    st.write(f"üí∞ A becs√ºlt feldolgoz√°si k√∂lts√©g eddig: **${price_input:.2f}** ({selected_model})")



with col_excel:
    
    st.subheader("üìÇ Excel f√°jlok bet√∂lt√©se")
    
    
    # --- Excel f√°jlok bet√∂lt√©se ---
    st.markdown("1) T√∂ltsd fel a **Mintav√©tel** Excel f√°jlt:")
    uploaded_excel_file_minta = st.file_uploader(
        "üì§ Mintav√©tel Excel felt√∂lt√©se",
        type=["xlsx"],
        accept_multiple_files=False,
        help="Az adatok az els≈ë munkalapon a 10. sort√≥l induljanak, √©s legyen 'Bizonylatsz√°m' nev≈± oszlop."
    )
    
    
    if uploaded_excel_file_minta:
        try:
            st.session_state.df_minta = pd.read_excel(uploaded_excel_file_minta, skiprows=range(1, 9))
            st.session_state.df_minta.columns = list(st.session_state.df_minta.iloc[0])
            st.session_state.df_minta = st.session_state.df_minta.iloc[1:]
            st.session_state.df_minta["Bizonylatsz√°m"] = st.session_state.df_minta["Bizonylatsz√°m"].astype(str)
        except:
            st.warning("‚ùå Nem siker√ºlt beolvasni a Mintav√©tel f√°jlt.")
    
    if len(st.session_state.df_minta) > 0:        
        st.write("‚úÖ **Mintav√©tel bet√∂ltve!** Els≈ë n√©h√°ny sor:")
        st.dataframe(st.session_state.df_minta.head(5))
    
    
    
    # NAV f√°jl
    st.markdown("2) T√∂ltsd fel a **NAV** Excel f√°jlt:")
    uploaded_excel_file_nav = st.file_uploader(
        "üì§ NAV Excel felt√∂lt√©se",
        type=["xlsx"],
        accept_multiple_files=False,
        help="Az adatok az els≈ë munkalapon a 6. sort√≥l induljanak, √©s legyen 'sz√°mlasorsz√°m' nev≈± oszlop."
    )    
    if uploaded_excel_file_nav:
        try:
            st.session_state.df_nav = pd.read_excel(uploaded_excel_file_nav, skiprows=5)
            st.session_state.df_nav["sz√°mlasorsz√°m"] = st.session_state.df_nav["sz√°mlasorsz√°m"].astype(str)
        except:
            st.warning("‚ùå Nem siker√ºlt beolvasni a NAV f√°jlt.")
    
    if len(st.session_state.df_nav) > 0:        
        st.write("‚úÖ **NAV f√°jl bet√∂ltve!** Els≈ë n√©h√°ny sor:")
        st.dataframe(st.session_state.df_nav.head(5))
    
    
    
    # Karton f√°jl
    st.markdown("3) T√∂ltsd fel a **Karton** Excel f√°jlt:")
    uploaded_excel_file_karton = st.file_uploader(
        "üì§ Karton Excel felt√∂lt√©se",
        type=["xlsx", "xls"],
        accept_multiple_files=False,
        help="Az adatok az els≈ë munkalapon az A1 cell√°t√≥l induljanak."
    )    
    
    default_invoice_column_karton = "Bizonylat"
    custom_colname_enabled_karton = st.checkbox("üîß Saj√°t oszlopn√©v megad√°sa a sz√°mlasz√°mhoz a Karton excelben (Alap√©rtelmezett: 'Bizonylat')", value=False)
    
    if custom_colname_enabled_karton:
        invoice_colname_karton = st.text_input("Add meg a sz√°mlasz√°mot tartalmaz√≥ oszlop nev√©t a Karton excelben:", value=default_invoice_column_karton)
    else:
        invoice_colname_karton = default_invoice_column_karton
    
    if uploaded_excel_file_karton:
        try:
            st.session_state.df_karton = pd.read_excel(uploaded_excel_file_karton)
            st.session_state.df_karton[invoice_colname_karton] = st.session_state.df_karton[invoice_colname_karton].astype(str)
        except:
            st.warning("‚ùå Nem siker√ºlt beolvasni a Karton f√°jlt.")
    
    if len(st.session_state.df_karton) > 0:        
        st.write("‚úÖ **Karton bet√∂ltve!** Els≈ë n√©h√°ny sor:")
        st.dataframe(st.session_state.df_karton.head(5))
 
    
 
st.title("üìÑ Ellen≈ërz√©sek")

col_left, col_right = st.columns([1, 1])  # nagyobb bal oldali has√°b

with col_left:
    st.subheader("üìé Kinyert adatok √∂sszef≈±z√©se √©s ellen≈ërz√©se: Mintav√©tel")
    
    invoice_colname_minta = "Bizonylatsz√°m"
        
    if st.button("üîó √ñsszef≈±z√©s √©s ellen≈ërz√©s a Mintav√©tel excellel"):
        # El≈ëfelt√©telek
        missing = []
        if not df_ready(st.session_state.df_extracted, required_cols=["Sz√°mlasz√°m", "Nett√≥ √°r"]):
            missing.append("Kinyert adatok (PDF feldolgoz√°s)")
        if not df_ready(st.session_state.df_minta, required_cols=["Bizonylatsz√°m", "√ârt√©k", "√ârt√©k deviza", "Devizanem"]):
            missing.append("Mintav√©tel Excel")
    
        if missing:
            need_msg(missing)
        else:
            try:
                df_minta = st.session_state.df_minta.copy()
                # Fejl√©cek biztons√°gos tiszt√≠t√°sa (nem haszn√°l .str-t)
                df_minta.columns = [str(c).strip() for c in df_minta.columns]
                df_minta["Bizonylatsz√°m"] = df_minta["Bizonylatsz√°m"].astype(str)
    
                df_gpt = st.session_state.df_extracted.copy()
                df_gpt["Sz√°mlasz√°m"] = df_gpt["Sz√°mlasz√°m"].astype(str)
    
                # ‚¨ÖÔ∏è GPT balra, Minta jobbra
                df_merged_minta = pd.merge(
                    df_gpt,
                    df_minta,
                    how="left",
                    left_on="Sz√°mlasz√°m",
                    right_on="Bizonylatsz√°m"
                )
    
                # Nett√≥ √∂sszehasonl√≠t√°s a mint√°val
                df_merged_minta["Nett√≥ egyezik?"] = df_merged_minta.apply(
                    lambda row: compare_with_tolerance(
                        get_minta_amount(row, huf_col="√ârt√©k", eur_col="√ârt√©k deviza", currency_col="Devizanem"),
                        normalize_number(row["Nett√≥ √°r"]),
                        tolerance=5
                    ),
                    axis=1
                )
    
                df_merged_minta["Minden egyezik?"] = df_merged_minta["Nett√≥ egyezik?"].apply(
                    lambda x: "‚úÖ Igen" if x else "‚ùå Nem"
                )
    
                st.session_state.df_merged_minta = df_merged_minta
    
                # üìä Statisztika
                total = len(df_merged_minta)
                matched = (df_merged_minta["Minden egyezik?"] == "‚úÖ Igen").sum()
                match_rate = round(100 * matched / total, 2)
    
                st.session_state.stats_minta = {
                    "√ñsszes sz√°mla": total,
                    "Minden egyez√©s": matched,
                    "Egyez√©si ar√°ny (%)": match_rate
                }
    
                st.success("‚úÖ √ñsszef≈±z√©s √©s ellen≈ërz√©s a Mintav√©tellel k√©sz!")
    
            except Exception as e:
                st.error(f"V√°ratlan hiba t√∂rt√©nt a Mintav√©tel √∂sszef≈±z√©s sor√°n: {e}")

    
    if "df_merged_minta" in st.session_state:
        st.write("üìÑ **√ñsszef≈±z√∂tt √©s ellen≈ërz√∂tt t√°bl√°zat ‚Äì Mintav√©tel:**")
        st.dataframe(st.session_state.df_merged_minta)
    
        csv_minta = st.session_state.df_merged_minta.to_csv(index=False).encode("utf-8")
    
        buffer = BytesIO()
        with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
            st.session_state.df_merged_minta.to_excel(writer, sheet_name='Minta', index=False)
            writer.close()
            st.download_button(
                label="üì• Let√∂lt√©s Excel (Mintav√©tel)",
                data=buffer,
                file_name='merged_minta.xlsx',
                mime='application/vnd.ms-excel'
            )
    
        st.markdown("### üìä Statisztika ‚Äì Mintav√©tel ellen≈ërz√©s")
        for k, v in st.session_state.stats_minta.items():
            st.write(f"**{k}:** {v}")
    


with col_right:
    st.subheader("üìé Kinyert adatok √∂sszef≈±z√©se √©s ellen≈ërz√©se: NAV")
    
    if st.button("üîó √ñsszef≈±z√©s √©s ellen≈ërz√©s a NAV excellel"):
        # El≈ëfelt√©telek
        missing = []
        if not df_ready(st.session_state.df_extracted, required_cols=["Sz√°mlasz√°m", "Brutt√≥ √°r", "Nett√≥ √°r", "√ÅFA"]):
            missing.append("Kinyert adatok (PDF feldolgoz√°s)")
        # A NAV f√°jlban legal√°bb a sz√°mlasz√°m √©s az √∂sszegek valamelyike legyen
        nav_required = ["sz√°mlasorsz√°m"]  # az √∂sszegek neve v√°ltozhat, ez√©rt ezt lent rugalmasan kezelj√ºk
        if not df_ready(st.session_state.df_nav, required_cols=nav_required):
            missing.append("NAV Excel")
    
        if missing:
            need_msg(missing)
        else:
            try:
                df_nav = st.session_state.df_nav.copy()
                df_nav.columns = [str(c).strip() for c in df_nav.columns]
                df_nav["sz√°mlasorsz√°m"] = df_nav["sz√°mlasorsz√°m"].astype(str)
    
                df_gpt = st.session_state.df_extracted.copy()
                df_gpt["Sz√°mlasz√°m"] = df_gpt["Sz√°mlasz√°m"].astype(str)
    
                df_merged_nav = pd.merge(
                    df_gpt,
                    df_nav,
                    how="left",
                    left_on="Sz√°mlasz√°m",
                    right_on="sz√°mlasorsz√°m"
                )
    
                # Oszlopnevek rugalmas keres√©se (k√ºl√∂nb√∂z≈ë exportok)
                brutto_col = "brutt√≥ √©rt√©k" if "brutt√≥ √©rt√©k" in df_merged_nav.columns else ("brutt√≥ √©rt√©k Ft" if "brutt√≥ √©rt√©k Ft" in df_merged_nav.columns else None)
                netto_col  = "nett√≥√©rt√©k"  if "nett√≥√©rt√©k"  in df_merged_nav.columns else ("nett√≥√©rt√©k Ft"  if "nett√≥√©rt√©k Ft"  in df_merged_nav.columns else None)
                afa_col    = "ad√≥√©rt√©k"    if "ad√≥√©rt√©k"    in df_merged_nav.columns else ("ad√≥√©rt√©k Ft"    if "ad√≥√©rt√©k Ft"    in df_merged_nav.columns else None)
    
                # Ha nincs egyik √∂sszegoszlop sem, adjunk bar√°ts√°gos jelz√©st
                amount_missing = []
                if brutto_col is None:
                    amount_missing.append("brutt√≥ √©rt√©k (NAV)")
                if netto_col is None:
                    amount_missing.append("nett√≥√©rt√©k (NAV)")
                if afa_col is None:
                    amount_missing.append("ad√≥√©rt√©k (NAV)")
                if amount_missing:
                    need_msg(amount_missing)
    
                # √ñsszegellen≈ërz√©sek (csak ha van megfelel≈ë NAV oszlop)
                df_merged_nav["Brutt√≥ egyezik?"] = df_merged_nav.apply(
                    lambda row: compare_with_tolerance(
                        normalize_number(row.get(brutto_col)) if brutto_col else None,
                        normalize_number(row.get("Brutt√≥ √°r")),
                    ),
                    axis=1
                )
    
                df_merged_nav["Nett√≥ egyezik?"] = df_merged_nav.apply(
                    lambda row: compare_with_tolerance(
                        normalize_number(row.get(netto_col)) if netto_col else None,
                        normalize_number(row.get("Nett√≥ √°r")),
                    ),
                    axis=1
                )
    
                df_merged_nav["√ÅFA egyezik?"] = df_merged_nav.apply(
                    lambda row: compare_with_tolerance(
                        normalize_number(row.get(afa_col)) if afa_col else None,
                        normalize_number(row.get("√ÅFA")),
                    ),
                    axis=1
                )
    
                df_merged_nav["Minden egyezik?"] = df_merged_nav.apply(
                    lambda row: "‚úÖ Igen" if (row["Brutt√≥ egyezik?"] and row["Nett√≥ egyezik?"] and row["√ÅFA egyezik?"]) else "‚ùå Nem",
                    axis=1
                )
    
                st.session_state.df_merged_nav = df_merged_nav
    
                # Statisztika
                total = len(df_merged_nav)
                matched_all = (df_merged_nav["Minden egyezik?"] == "‚úÖ Igen").sum()
                match_rate = round(100 * matched_all / total, 2)
    
                st.session_state.stats_nav = {
                    "√ñsszes sz√°mla": total,
                    "Minden egyez√©s": matched_all,
                    "Teljes egyez√©si ar√°ny (%)": match_rate
                }
    
                st.success("‚úÖ NAV f√°jllal val√≥ √∂sszef≈±z√©s √©s ellen≈ërz√©s k√©sz!")
    
            except Exception as e:
                st.error(f"V√°ratlan hiba t√∂rt√©nt a NAV √∂sszef≈±z√©s sor√°n: {e}")

    
    if "df_merged_nav" in st.session_state:
        st.write("üìÑ **√ñsszef≈±z√∂tt √©s ellen≈ërz√∂tt t√°bl√°zat ‚Äì NAV:**")
        st.dataframe(st.session_state.df_merged_nav)
    
        # Excel let√∂lt√©s el≈ëk√©sz√≠t√©s
        buffer = BytesIO()
        with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
            st.session_state.df_merged_nav.to_excel(writer, sheet_name='NAV √∂sszehasonl√≠t√°s', index=False)
            writer.close()
    
        st.download_button(
            label="üì• Let√∂lt√©s Excel (NAV)",
            data=buffer,
            file_name="merged_nav.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    
        st.markdown("### üìä Statisztika ‚Äì NAV √∂sszehasonl√≠t√°s")
        for k, v in st.session_state.stats_nav.items():
            st.write(f"**{k}:** {v}")
    



asdd = """
st.subheader("üìé Kinyert adatok √∂sszef≈±z√©se: Karton EZT EGYEL≈êRE NEM CSIN√ÅLTAM MEG")

if st.button("üîó √ñsszef≈±z√©s a Kartonnal"):
    try:
        df_merged_karton = pd.merge(
            st.session_state.df_extracted,
            st.session_state.df_karton,
            how="left",
            left_on="Sz√°mlasz√°m",
            right_on=invoice_colname_karton
        )

        matched_karton = df_merged_karton[invoice_colname_karton].notna().sum()
        total_karton = len(st.session_state.df_extracted)
        unmatched_karton = total_karton - matched_karton
        match_rate_karton = round(100 * matched_karton / total_karton, 2)

        st.session_state.df_merged_karton = df_merged_karton
        st.session_state.stats_karton = {
            "√ñsszes sz√°mla": total_karton,
            "Karton egyez√©s": matched_karton,
            "Hi√°nyz√≥ egyez√©s": unmatched_karton,
            "Egyez√©si ar√°ny (%)": match_rate_karton
        }

        st.success("‚úÖ Karton √∂sszef≈±z√©s k√©sz!")

    except Exception as e:
        st.error(f"‚ùå Hiba t√∂rt√©nt a Karton √∂sszef≈±z√©s sor√°n: {e}")

if "df_merged_karton" in st.session_state:
    st.write("üìÑ **√ñsszef≈±z√∂tt t√°bl√°zat ‚Äì Karton:**")
    st.dataframe(st.session_state.df_merged_karton)

    csv_karton = st.session_state.df_merged_karton.to_csv(index=False).encode("utf-8")
    st.download_button("üì• Let√∂lt√©s CSV (Karton)", csv_karton, "merged_karton.csv", "text/csv")

    st.markdown("### üìä Statisztika ‚Äì Karton √∂sszef≈±z√©s")
    for k, v in st.session_state.stats_karton.items():
        st.write(f"**{k}:** {v}")
"""








local_test = r"""

os.listdir('./')


import tomllib

secrets_path = r"C:\Users\abele\.streamlit\secrets.toml"

with open(secrets_path, "rb") as f:
    secrets = tomllib.load(f)

openai.api_key = secrets["OPENAI_API_KEY"]

MODEL = "gpt-4.1"  # cheapest useful model
PDF_FILE = "9601013656.pdf"  # <-- replace with your own file path


with open(PDF_FILE, "rb") as f:
    text = extract_text_from_pdf(f)


# 2) GPT extraction
rows, tokens_used = extract_data_with_gpt(PDF_FILE, text, MODEL)


# 3) Create DataFrame
df = pd.DataFrame(rows, columns=[
    "F√°jl", "Elad√≥", "Vev≈ë", "Sz√°mlasz√°m", "Sz√°mla d√°tum",
    "Brutt√≥ √°r", "Nett√≥ √°r", "√ÅFA", "P√©nznem", "√Årfolyam"
])





"""



local_test = r"""
df_extracted = pd.read_csv('extract_data.csv')
df_minta = pd.read_excel('Mintav√©tel_k√∂lts√©gek_Sonneveld √©s ellen√Ørz√©s.xlsx', sheet_name='Mintav√©tel', skiprows = range(1, 9))
df_minta.columns = list(df_minta.iloc[0])
df_minta = df_minta.iloc[1:]
df_minta["Bizonylatsz√°m"] = df_minta["Bizonylatsz√°m"].astype(str)
df_karton = pd.read_excel('K√∂nyvel√©si karton 2024_Sonneveld Kft.xlsx', sheet_name='Munka1')

df_temp = pd.merge(df_minta, df_extracted, how='outer', left_on='Bizonylatsz√°m', right_on='Sz√°mlasz√°m')
nr_of_columns = len(df_temp.columns)

df_temp = pd.merge(df_temp, df_karton, how='left', left_on='Bizonylatsz√°m', right_on='Bizonylat')

column_to_compare = 'Bizonylatsz√°m'
columns_to_delete = df_temp.columns[:nr_of_columns]
df_merged = replace_successive_duplicates(df_temp, column_to_compare, columns_to_delete)

"""
